{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assuming that we have our data, this will be the\n",
    "data preprocessing step in which we:\n",
    "1- Clean the dataset\n",
    "2- Extract features\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Region:\n",
    "    \n",
    "    def __init__(self, num_pins, num_modules, total_area, num_tracks, net_cuts_num):\n",
    "        self.num_pins = num_pins\n",
    "        self.num_modules = num_modules\n",
    "        self.total_area = total_area\n",
    "        self.num_tracks = num_tracks\n",
    "        self.net_cuts_num = net_cuts_num\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'num_pins': self.num_pins,\n",
    "            'num_modules': self.num_modules,\n",
    "            'total_area': self.total_area,\n",
    "            'num_tracks': self.num_tracks,\n",
    "            'net_cut_num': self.net_cuts_num\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modules_names</th>\n",
       "      <th>area</th>\n",
       "      <th>pin_connections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a0</td>\n",
       "      <td>224</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a10</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a100</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1000</td>\n",
       "      <td>224</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19596</th>\n",
       "      <td>p95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19597</th>\n",
       "      <td>p96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19598</th>\n",
       "      <td>p97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19599</th>\n",
       "      <td>p98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19600</th>\n",
       "      <td>p99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19601 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      modules_names  area  pin_connections\n",
       "0                a0   224                6\n",
       "1                a1    64                3\n",
       "2               a10    96                2\n",
       "3              a100    64                3\n",
       "4             a1000   224                6\n",
       "...             ...   ...              ...\n",
       "19596           p95     0                1\n",
       "19597           p96     0                1\n",
       "19598           p97     0                1\n",
       "19599           p98     0                1\n",
       "19600           p99     0                1\n",
       "\n",
       "[19601 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin_names_file = open('ibm02/ibm02.net', 'r')\n",
    "pin_names_area = open('ibm02/ibm02.are', 'r')\n",
    "\n",
    "pins_info_area = {}\n",
    "modules_pins = {}\n",
    "for num_line, line in enumerate(pin_names_file.readlines()):\n",
    "    if num_line == 4:\n",
    "        num_of_modules = int(line)\n",
    "    if num_line == 2:\n",
    "        num_nets = int(line)\n",
    "    if num_line == 1:\n",
    "        num_of_pins = int(line)\n",
    "    if not line.split(' ')[0].replace('\\n', '').isdigit():\n",
    "        if line.split(' ')[0] not in modules_pins:\n",
    "            modules_pins[line.split(' ')[0]] = 1\n",
    "        else:\n",
    "            modules_pins[line.split(' ')[0]]+=1\n",
    "\n",
    "for line in pin_names_area.readlines():\n",
    "    info = line.split(' ')\n",
    "    pins_info_area[info[0]] = int(info[1])\n",
    "\n",
    "pin_names_file.close()\n",
    "pin_names_area.close()\n",
    "\n",
    "# print(len(pins_info_area))\n",
    "# print(len(modules_pins))\n",
    "# print(num_of_modules)\n",
    "# print(num_of_pins)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "sorted_pins_area = dict(sorted(pins_info_area.items()))\n",
    "sorted_modules = dict(sorted(modules_pins.items()))\n",
    "\n",
    "data['modules_names'] = sorted_pins_area.keys()\n",
    "data['area'] = sorted_pins_area.values()\n",
    "data['pin_connections'] = sorted_modules.values()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pins</th>\n",
       "      <th>num_modules</th>\n",
       "      <th>total_area</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>net_cut_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>2380</td>\n",
       "      <td>140</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>1870</td>\n",
       "      <td>110</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>16</td>\n",
       "      <td>2210</td>\n",
       "      <td>130</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>2958</td>\n",
       "      <td>174</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>16</td>\n",
       "      <td>2108</td>\n",
       "      <td>124</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>57</td>\n",
       "      <td>16</td>\n",
       "      <td>1870</td>\n",
       "      <td>110</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "      <td>10234</td>\n",
       "      <td>602</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>72</td>\n",
       "      <td>16</td>\n",
       "      <td>2380</td>\n",
       "      <td>140</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>2448</td>\n",
       "      <td>144</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>1938</td>\n",
       "      <td>114</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_pins  num_modules  total_area  num_tracks  net_cut_num\n",
       "0           70           16        2380         140          279\n",
       "1           63           16        1870         110          310\n",
       "2           72           16        2210         130          272\n",
       "3           65           16        2958         174          301\n",
       "4           67           16        2108         124          292\n",
       "...        ...          ...         ...         ...          ...\n",
       "1204        57           16        1870         110          343\n",
       "1205        61           16       10234         602          321\n",
       "1206        72           16        2380         140          272\n",
       "1207        63           16        2448         144          310\n",
       "1208        62           16        1938         114          315\n",
       "\n",
       "[1209 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_data = [data[i:i+16] for i in range(0,data.shape[0],16)]\n",
    "\n",
    "final_dataset = []\n",
    "\n",
    "for i in chunks_data:\n",
    "    chunk = pd.DataFrame(i)\n",
    "    total_pins = chunk['pin_connections'].sum()\n",
    "    num_modules = len(chunk)\n",
    "    total_area = int(chunk['area'].sum() + chunk['area'].mean())\n",
    "    num_tracks = int(chunk['area'].mean())\n",
    "    net_cuts_num = num_nets//total_pins\n",
    "    \n",
    "    new_region = Region(total_pins, num_modules, total_area, num_tracks, net_cuts_num)\n",
    "    final_dataset.append(new_region)\n",
    "\n",
    "final = pd.DataFrame.from_records([s.to_dict() for s in final_dataset])\n",
    "final = final[final['total_area'] != 0]\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pins</th>\n",
       "      <th>num_modules</th>\n",
       "      <th>total_area</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>net_cut_num</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>2380</td>\n",
       "      <td>140</td>\n",
       "      <td>279</td>\n",
       "      <td>0.997243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>1870</td>\n",
       "      <td>110</td>\n",
       "      <td>310</td>\n",
       "      <td>0.997243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>16</td>\n",
       "      <td>2210</td>\n",
       "      <td>130</td>\n",
       "      <td>272</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>2958</td>\n",
       "      <td>174</td>\n",
       "      <td>301</td>\n",
       "      <td>0.999030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>16</td>\n",
       "      <td>2108</td>\n",
       "      <td>124</td>\n",
       "      <td>292</td>\n",
       "      <td>0.998979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>57</td>\n",
       "      <td>16</td>\n",
       "      <td>1870</td>\n",
       "      <td>110</td>\n",
       "      <td>343</td>\n",
       "      <td>0.998315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "      <td>10234</td>\n",
       "      <td>602</td>\n",
       "      <td>321</td>\n",
       "      <td>0.999847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>72</td>\n",
       "      <td>16</td>\n",
       "      <td>2380</td>\n",
       "      <td>140</td>\n",
       "      <td>272</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>2448</td>\n",
       "      <td>144</td>\n",
       "      <td>310</td>\n",
       "      <td>0.997243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>1938</td>\n",
       "      <td>114</td>\n",
       "      <td>315</td>\n",
       "      <td>0.997243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_pins  num_modules  total_area  num_tracks  net_cut_num     label\n",
       "0           70           16        2380         140          279  0.997243\n",
       "1           63           16        1870         110          310  0.997243\n",
       "2           72           16        2210         130          272  1.000000\n",
       "3           65           16        2958         174          301  0.999030\n",
       "4           67           16        2108         124          292  0.998979\n",
       "...        ...          ...         ...         ...          ...       ...\n",
       "1204        57           16        1870         110          343  0.998315\n",
       "1205        61           16       10234         602          321  0.999847\n",
       "1206        72           16        2380         140          272  1.000000\n",
       "1207        63           16        2448         144          310  0.997243\n",
       "1208        62           16        1938         114          315  0.997243\n",
       "\n",
       "[1209 rows x 6 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for index, row in final.iterrows():\n",
    "    labels.append((int(row['num_pins'])*int(row['num_modules'])*int(row['num_tracks'])*int(row['net_cut_num']))/(int(row['total_area'])))\n",
    "\n",
    "labels = [float(i)/max(labels) for i in labels]\n",
    "final[\"label\"] = labels\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_relative_error(actual, predicted):\n",
    "    rel_err=[]\n",
    "    actual,predicted=np.array(actual), np.array(predicted)\n",
    "    for i in range(0,len(actual)):\n",
    "        err=abs(actual[i]-predicted[i])/(actual[i]+1)\n",
    "        rel_err.append(err)\n",
    "    return np.mean(rel_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_technique():\n",
    "    \n",
    "    n_iter_search = 20\n",
    "    \n",
    "    features=final.drop(['label'], axis='columns')\n",
    "    print(features)\n",
    "    label=final['label']\n",
    "    \n",
    "    train_features, test_features, train_label, test_label = train_test_split(features, label, test_size=0.2)\n",
    "    \n",
    "    rf_avg_mre, svr_avg_mre = [], []\n",
    "    rf_avg_mae, svr_avg_mae = [], []\n",
    "    rf_avg_rmse, svr_avg_rmse = [], []\n",
    "    \n",
    "    for run in range(30):\n",
    "        print('run:', run+1)\n",
    "        \n",
    "        kf = KFold(n_splits=10, shuffle=True)\n",
    "        i=1\n",
    "        \n",
    "        rf_mre, svr_mre = [], []\n",
    "        rf_mae, svr_mae = [], []\n",
    "        rf_rmse, svr_rmse = [], []\n",
    "        \n",
    "        for train_index, test_index in kf.split(train_features):\n",
    "            print('fold number:', i)\n",
    "            i+=1\n",
    "            \n",
    "            x_train, x_test = train_features.iloc[train_index], train_features.iloc[test_index]\n",
    "            y_train, y_test = train_label.iloc[train_index], train_label.iloc[test_index]\n",
    "            \n",
    "            params_rf = { \n",
    "                            \"n_estimators\": stats.randint(30, 200),\n",
    "                            \"min_samples_leaf\": stats.randint(30, 50),\n",
    "                            \"max_depth\": stats.randint(20, 50)\n",
    "                        }\n",
    "            \n",
    "            params_svr = {\n",
    "                            \"C\": stats.uniform(2, 10),\n",
    "                            \"gamma\": stats.uniform(0.1, 1)\n",
    "                         }\n",
    "            \n",
    "            \n",
    "            print('RF ** Training ...')\n",
    "            rand_search_rf = RandomizedSearchCV(RandomForestRegressor(), params_rf, cv=n_iter_search)\n",
    "            rand_search_rf.fit(x_train, y_train)\n",
    "            best_tuned_rf = rand_search_rf.best_estimator_\n",
    "            print('RF ** Predicting ...')\n",
    "            y_pred = best_tuned_rf.predict(test_features)\n",
    "            rf_mre.append(mean_relative_error(test_label, y_pred))\n",
    "            rf_mae.append(metrics.mean_absolute_error(test_label, y_pred))\n",
    "            rf_rmse.append(math.sqrt(metrics.mean_squared_error(test_label, y_pred)))\n",
    "            \n",
    "            print('SVM ** Training ...')\n",
    "            rand_search_svm = RandomizedSearchCV(SVR(), params_svr, cv=n_iter_search)\n",
    "            rand_search_svm.fit(x_train, y_train)\n",
    "            best_tuned_svm = rand_search_svm.best_estimator_\n",
    "            print('SVM ** Predicting ...')\n",
    "            y_pred = best_tuned_svm.predict(test_features)\n",
    "            svr_mre.append(mean_relative_error(test_label, y_pred))\n",
    "            svr_mae.append(metrics.mean_absolute_error(test_label, y_pred))\n",
    "            svr_rmse.append(math.sqrt(metrics.mean_squared_error(test_label, y_pred)))\n",
    "            \n",
    "            \n",
    "        rf_avg_mre.append(np.mean(rf_mre))\n",
    "        rf_avg_mae.append(np.mean(rf_mae))\n",
    "        rf_avg_rmse.append(np.mean(rf_rmse))\n",
    "        \n",
    "        svr_avg_mre.append(np.mean(svr_mre))\n",
    "        svr_avg_mae.append(np.mean(svr_mae))\n",
    "        svr_avg_rmse.append(np.mean(svr_rmse))\n",
    "        \n",
    "    print(rf_avg_mre)\n",
    "    print('########################################################')\n",
    "    print(rf_avg_mae)\n",
    "    print('########################################################')\n",
    "    print(rf_avg_rmse)\n",
    "    print('########################################################')\n",
    "    print(svr_avg_mre)\n",
    "    print('########################################################')\n",
    "    print(svr_avg_mae)\n",
    "    print('########################################################')\n",
    "    print(svr_avg_rmse)\n",
    "    print('########################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      num_pins  num_modules  total_area  num_tracks  net_cut_num\n",
      "0           70           16        2380         140          279\n",
      "1           63           16        1870         110          310\n",
      "2           72           16        2210         130          272\n",
      "3           65           16        2958         174          301\n",
      "4           67           16        2108         124          292\n",
      "...        ...          ...         ...         ...          ...\n",
      "1204        57           16        1870         110          343\n",
      "1205        61           16       10234         602          321\n",
      "1206        72           16        2380         140          272\n",
      "1207        63           16        2448         144          310\n",
      "1208        62           16        1938         114          315\n",
      "\n",
      "[1209 rows x 5 columns]\n",
      "run: 1\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 2\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 3\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 4\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 5\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 6\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 7\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 8\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 9\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 10\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 11\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 12\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 13\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 14\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 15\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 16\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ** Predicting ...\n",
      "run: 17\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 18\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 19\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 20\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 21\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 22\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 23\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 24\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 25\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 26\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 27\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 28\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 29\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "run: 30\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "fold number: 1\n",
      "RF ** Training ...\n",
      "RF ** Predicting ...\n",
      "SVM ** Training ...\n",
      "SVM ** Predicting ...\n",
      "[0.00022673232685482898, 0.00022718032962343917, 0.0002288947486583502, 0.00022543658224427276, 0.000231753836056309, 0.0002290571025770554, 0.0002264070145062792, 0.0002343654434227564, 0.00023021947379753922, 0.0002306028100463288, 0.00022751336826033682, 0.00023632727687810618, 0.00023147246975015935, 0.0002264008876608273, 0.00022784947150752082, 0.00022795791298740317, 0.00023089929333886054, 0.00022681120837892682, 0.00022579742273455306, 0.00022971129658322094, 0.00022838513715029395, 0.00022969144263354147, 0.00022644555508002467, 0.00022525914202087553, 0.00023003686379063112, 0.0002287598698519494, 0.00022945271860208465, 0.00022924075122040963, 0.00022903698048729152, 0.0002305410042347217]\n",
      "########################################################\n",
      "[0.00045315851755568456, 0.00045405514867331316, 0.0004574817957999634, 0.000450568750928808, 0.00046319661946956205, 0.0004578052287011553, 0.0004525084734942138, 0.0004684160114346996, 0.0004601296047993876, 0.0004608962486227373, 0.0004547216990455825, 0.0004723367989965273, 0.00046263344201204453, 0.0004524958095985662, 0.00045539307896689206, 0.0004556103783433041, 0.0004614888910341716, 0.0004533162864425399, 0.0004512912696654603, 0.0004591119090888148, 0.0004564626169608219, 0.00045907421188432927, 0.0004525860710773093, 0.00045021394211049095, 0.00045976346594356674, 0.00045721126122884976, 0.0004585947886797408, 0.0004581723132928837, 0.0004577652721551674, 0.00046077169050697875]\n",
      "########################################################\n",
      "[0.0006053360020500687, 0.0006068365035848071, 0.0006111823213281721, 0.0006031326014587148, 0.0006154310554152376, 0.000612735424210512, 0.0006058578983953601, 0.0006256592258906989, 0.0006142014826202968, 0.0006124792739166749, 0.0006090395282091573, 0.0006300220825698665, 0.0006187050738403413, 0.0006070682006353336, 0.0006104762079448894, 0.0006096865152715707, 0.000615328664610573, 0.0006049264273033895, 0.000605560368262187, 0.0006152071764155989, 0.0006081553289509185, 0.0006146467481137867, 0.0006049592906248668, 0.000602998229984753, 0.0006161213407963103, 0.0006128698263720022, 0.0006147177643103753, 0.0006123316715530723, 0.0006115712286045426, 0.0006154164845866685]\n",
      "########################################################\n",
      "[0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005349085951226025, 0.0005349085951226025, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756]\n",
      "########################################################\n",
      "[0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010692866161616035, 0.0010692866161616037, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492]\n",
      "########################################################\n",
      "[0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012923775033414134, 0.0012923775033414134, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "run_technique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002289413246979633\n",
      "0.0004575743865504522\n",
      "0.0006117553315943582\n",
      "0.0005350361128138571\n",
      "0.0010695426299537133\n",
      "0.0012931324066544029\n"
     ]
    }
   ],
   "source": [
    "rf_avg_rme_f = [0.00022673232685482898, 0.00022718032962343917, 0.0002288947486583502, 0.00022543658224427276, 0.000231753836056309, 0.0002290571025770554, 0.0002264070145062792, 0.0002343654434227564, 0.00023021947379753922, 0.0002306028100463288, 0.00022751336826033682, 0.00023632727687810618, 0.00023147246975015935, 0.0002264008876608273, 0.00022784947150752082, 0.00022795791298740317, 0.00023089929333886054, 0.00022681120837892682, 0.00022579742273455306, 0.00022971129658322094, 0.00022838513715029395, 0.00022969144263354147, 0.00022644555508002467, 0.00022525914202087553, 0.00023003686379063112, 0.0002287598698519494, 0.00022945271860208465, 0.00022924075122040963, 0.00022903698048729152, 0.0002305410042347217]\n",
    "print(sum(rf_avg_rme_f)/len(rf_avg_rme_f))\n",
    "rf_avg_mae_f = [0.00045315851755568456, 0.00045405514867331316, 0.0004574817957999634, 0.000450568750928808, 0.00046319661946956205, 0.0004578052287011553, 0.0004525084734942138, 0.0004684160114346996, 0.0004601296047993876, 0.0004608962486227373, 0.0004547216990455825, 0.0004723367989965273, 0.00046263344201204453, 0.0004524958095985662, 0.00045539307896689206, 0.0004556103783433041, 0.0004614888910341716, 0.0004533162864425399, 0.0004512912696654603, 0.0004591119090888148, 0.0004564626169608219, 0.00045907421188432927, 0.0004525860710773093, 0.00045021394211049095, 0.00045976346594356674, 0.00045721126122884976, 0.0004585947886797408, 0.0004581723132928837, 0.0004577652721551674, 0.00046077169050697875]\n",
    "print(sum(rf_avg_mae_f)/len(rf_avg_mae_f))\n",
    "rf_avg_rmse_f = [0.0006053360020500687, 0.0006068365035848071, 0.0006111823213281721, 0.0006031326014587148, 0.0006154310554152376, 0.000612735424210512, 0.0006058578983953601, 0.0006256592258906989, 0.0006142014826202968, 0.0006124792739166749, 0.0006090395282091573, 0.0006300220825698665, 0.0006187050738403413, 0.0006070682006353336, 0.0006104762079448894, 0.0006096865152715707, 0.000615328664610573, 0.0006049264273033895, 0.000605560368262187, 0.0006152071764155989, 0.0006081553289509185, 0.0006146467481137867, 0.0006049592906248668, 0.000602998229984753, 0.0006161213407963103, 0.0006128698263720022, 0.0006147177643103753, 0.0006123316715530723, 0.0006115712286045426, 0.0006154164845866685]\n",
    "print(sum(rf_avg_rmse_f)/ len(rf_avg_rmse_f))\n",
    "svr_avg_rme_f = [0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005349085951226025, 0.0005349085951226025, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756, 0.0005350452212203756]\n",
    "print(sum(svr_avg_rme_f)/ len(svr_avg_rme_f))\n",
    "svr_avg_mae_f = [0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010692866161616035, 0.0010692866161616037, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492, 0.0010695609166531492, 0.0010695609166531494, 0.0010695609166531492]\n",
    "print(sum(svr_avg_mae_f)/ len(svr_avg_mae_f))\n",
    "svr_avg_rmse_f = [0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012923775033414134, 0.0012923775033414134, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163, 0.0012931863283196163, 0.0012931863283196165, 0.0012931863283196163]\n",
    "print(sum(svr_avg_rmse_f)/ len(svr_avg_rmse_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
